# Partitioning Advisor (Capstone)

A lightweight, workload-aware partitioning advisor: given **data size** and **query type**, it recommends **Hive partitioning** vs **Spark repartition** and the partition count.

---

## Data dependency

The Advisor uses the **experiment summary** `experiment_summary.csv`, which is generated from existing experiment results by:

```bash
# Run from the project root
python3 advisor/scripts/build_summary.py
```

- **Input**: `*_results.csv` and `*_stats/*.csv` under `stats_collection_tools/`.
- **Output**: `advisor/experiment_summary.csv` (see [Experiment design](../docs/EXPERIMENT_DESIGN.md)).

Run the command above first if the summary is missing.

---

## Usage

### CLI (recommended)

From the project root:

```bash
python3 advisor/advisor.py --data-size 50mb --query-type join
python3 advisor/advisor.py -s 5mb -q window --objective runtime
python3 advisor/advisor.py -s 500mb -q aggregate -v   # -v prints runtime/cpu/memory details
```

- `--data-size` / `-s`: Data size, e.g. 5mb, 50mb, 500mb, 5gb.
- `--query-type` / `-q`: Query type: aggregate, join, window.
- `--objective` / `-o`: Optimize for runtime (default), cpu, or memory (falls back to runtime if resource data is missing).

### Call from code

```python
from recommend import recommend

strategy, num_partitions, reason, row = recommend("50mb", "join")
# strategy == "spark_repartition", num_partitions == 4, reason is the explanation string
```

---

## Directory layout

```
advisor/
├── README.md                 # This file
├── experiment_summary.csv    # Experiment summary (generated by scripts/build_summary.py)
├── recommend.py              # recommend(data_size, query_type, objective=...)
├── advisor.py                # CLI entry
└── scripts/
    ├── build_summary.py      # Merges runtime + resource stats → experiment_summary.csv
    ├── evaluate_advisor.py  # Compares recommendations to true best; reports agreement rate
    └── plot_runtime.py      # Plots runtime comparison (requires matplotlib)
```

---

## Summary table schema (overview)

| Column           | Description                                      |
| ---------------- | ------------------------------------------------- |
| data_size        | 5mb / 50mb / 500mb / 5gb                          |
| query_type       | aggregate / join / window                         |
| strategy         | hive / spark_repartition                          |
| num_partitions   | 4 / 16 / 32 (spark_repartition only) or empty     |
| runtime_seconds  | Minimum runtime (seconds)                         |
| max_cpu_pct      | Max CPU usage (%)                                 |
| max_memory_mib   | Max memory (MiB)                                  |

See [docs/EXPERIMENT_DESIGN.md](../docs/EXPERIMENT_DESIGN.md) for full details.
